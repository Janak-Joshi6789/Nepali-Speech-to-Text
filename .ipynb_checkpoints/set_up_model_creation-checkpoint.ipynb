{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bbb1d10-e0a4-436e-8bfd-b5a788cf60da",
   "metadata": {},
   "source": [
    "<h5>Let's install both datasets and transformers from master. <br>\n",
    "Also, we need the soundfile package to load audio files <br>\n",
    "and the jiwer to evaluate our fine-tuned model using the word error rate (WER) metric </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e533403-f863-4b75-b776-b9f66679b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c303066-a9e8-4896-8674-5583de328485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07f02923-a555-4f32-a96d-3ceee0bb6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "058ed069-74f7-4062-a2e2-e1ecc4e20e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad4d484d-8c8c-4955-ba50-b4b0e2389f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jiwer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b502340-0670-4634-b85c-7ec4210b62e6",
   "metadata": {},
   "source": [
    "<h5>Upload your training checkpoints directly to the Hugging Face Hub while training. </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "73d2c78a-42ad-460c-8543-cec758bfadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "11e8e43d-5f52-4ac2-9efe-5f32243d5e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "5050d017-1eaf-44bf-bde9-7a19f63e0bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "c1ef4fdf-c908-442d-b476-929afd753b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !jupyter nbextension enable --py widgetsnbextension\n",
    "# !jupyter nbextension install --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "99e3b3a0-b707-4b22-8fde-fced1ef160bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CODE IS TO BE RAN ON TERMINAL\n",
    "# pip install jupyter_contrib_nbextensions\n",
    "# jupyter contrib nbextension install --user\n",
    "# jupyter nbextension enable varInspector/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "1901e717-8913-4daa-b238-d0834f3431c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8318a0-3722-432c-a729-385361908058",
   "metadata": {},
   "source": [
    "<H5>\n",
    "Let's start by loading the dataset and taking a look at its structure.\n",
    "</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "e74c03ad-e30c-42d4-bba9-79c9ca5ac43c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "29b4a3d5-9600-4148-9cd0-ae6607e392be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset #65\n",
    "from evaluate import load #55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "5638a5c9-8c2e-47b3-8f1d-a13a3ff2b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "c9934882-fec7-4e78-b0f0-ea8c38af1355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "eb4a3e5e-9fea-4a7c-b439-186567f10aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"0e7280bb2e4bfc81c8c0b019860ef8f11041f4d4\") # add wandb API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "6089f83f-cd88-4749-916c-e9c666e1f123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:kvj11qqo) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">volcanic-tree-5</strong> at: <a href='https://wandb.ai/770310-khwopa-engineering-college/speech/runs/kvj11qqo' target=\"_blank\">https://wandb.ai/770310-khwopa-engineering-college/speech/runs/kvj11qqo</a><br/> View project at: <a href='https://wandb.ai/770310-khwopa-engineering-college/speech' target=\"_blank\">https://wandb.ai/770310-khwopa-engineering-college/speech</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241210_123729-kvj11qqo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:kvj11qqo). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\hp\\Desktop\\Project007\\Automatic-Nepali-Speech-Recognition-and-Summarizer\\Training\\ASR\\asr_wav2vec\\wandb\\run-20241210_124110-bjvksfps</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/770310-khwopa-engineering-college/speech/runs/bjvksfps' target=\"_blank\">generous-glitter-6</a></strong> to <a href='https://wandb.ai/770310-khwopa-engineering-college/speech' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/770310-khwopa-engineering-college/speech' target=\"_blank\">https://wandb.ai/770310-khwopa-engineering-college/speech</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/770310-khwopa-engineering-college/speech/runs/bjvksfps' target=\"_blank\">https://wandb.ai/770310-khwopa-engineering-college/speech/runs/bjvksfps</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/770310-khwopa-engineering-college/speech/runs/bjvksfps?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x213ed2a1750>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"speech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "fb11ed8e-39b6-47ca-a288-64a78cfcbf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir csv_files\n",
    "# !mkdir trained_models\n",
    "# !mkdir checkpoints\n",
    "# !mkdir tokenizer\n",
    "# !mkdir processor \n",
    "# !mkdir feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "405c1362-3443-465c-8f12-ce6204c80888",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_folder_path = './csv_files'\n",
    "trained_model_path = './trained_models/wav2vec0.8dropout'\n",
    "processor_path = './processor/wav2vec0.8dropout'\n",
    "checkpoints_path = './checkpoints/'\n",
    "tokenizer_path = './tokenizer/'\n",
    "feature_extractor_path = './feature_extractor/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "dd77a81b-9e58-4c0b-90b7-3bb1f027a904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "a5615175-e866-471f-9194-f794d46f24fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_path = './input/cleaned-asr-data/transcript_durations/line_index.csv'\n",
    "df = pd.read_csv(transcript_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "9390dde0-3ab2-4709-afef-594e52769705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       दीपा धामीको जन्म सुदूरपश्चिम नेपालको बझाङ जिल्...\n",
       "1       डिग्रा देवीको जन्म सुदूरपश्चिम नेपालको बझाङ जि...\n",
       "2       टेकबहादुर ऐरको जन्म सुदूरपश्चिम नेपालको डडेलधु...\n",
       "3       सुमन शेखरमानन्धर नेपालको कृषि अर्थविद् तथा गाय...\n",
       "4       आधिकारिक रूपमा पहिलो नेपाली चलचित्र नायक शिव श...\n",
       "                              ...                        \n",
       "2059                यहाँका अधिकांश जनता कृषिमै आधारित छन्\n",
       "2060    भीमसेनले किच्चकको बध गरे रगत पखाल्न उनले हानेक...\n",
       "2061         यो पत्रिकाको प्रकाशक लालचन्द्र राजभण्डारी हो\n",
       "2062              कालिङ्पोङमा धेरै राम्रा रेस्टुरेन्ट छन्\n",
       "2063                मेरो वर्गको समाजले मलाई संस्कार दिएको\n",
       "Name: labels, Length: 2064, dtype: object"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "bdb65ff1-6336-4b20-a62c-50376a702556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2064, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./input/cleaned-asr-data/wavs/nep_0258_0119737...</td>\n",
       "      <td>दीपा धामीको जन्म सुदूरपश्चिम नेपालको बझाङ जिल्...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./input/cleaned-asr-data/wavs/nep_0258_0461984...</td>\n",
       "      <td>डिग्रा देवीको जन्म सुदूरपश्चिम नेपालको बझाङ जि...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./input/cleaned-asr-data/wavs/nep_0258_0576399...</td>\n",
       "      <td>टेकबहादुर ऐरको जन्म सुदूरपश्चिम नेपालको डडेलधु...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./input/cleaned-asr-data/wavs/nep_0258_0707220...</td>\n",
       "      <td>सुमन शेखरमानन्धर नेपालको कृषि अर्थविद् तथा गाय...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./input/cleaned-asr-data/wavs/nep_0258_0838627...</td>\n",
       "      <td>आधिकारिक रूपमा पहिलो नेपाली चलचित्र नायक शिव श...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  ./input/cleaned-asr-data/wavs/nep_0258_0119737...   \n",
       "1  ./input/cleaned-asr-data/wavs/nep_0258_0461984...   \n",
       "2  ./input/cleaned-asr-data/wavs/nep_0258_0576399...   \n",
       "3  ./input/cleaned-asr-data/wavs/nep_0258_0707220...   \n",
       "4  ./input/cleaned-asr-data/wavs/nep_0258_0838627...   \n",
       "\n",
       "                                              labels  \n",
       "0  दीपा धामीको जन्म सुदूरपश्चिम नेपालको बझाङ जिल्...  \n",
       "1  डिग्रा देवीको जन्म सुदूरपश्चिम नेपालको बझाङ जि...  \n",
       "2  टेकबहादुर ऐरको जन्म सुदूरपश्चिम नेपालको डडेलधु...  \n",
       "3  सुमन शेखरमानन्धर नेपालको कृषि अर्थविद् तथा गाय...  \n",
       "4  आधिकारिक रूपमा पहिलो नेपाली चलचित्र नायक शिव श...  "
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = [\"path\",\"labels\"]\n",
    "audio_path = './input/cleaned-asr-data/wavs/'\n",
    "transcript_path = './input/cleaned-asr-data/transcript_durations/line_index.csv'\n",
    "df = pd.read_csv(transcript_path,usecols=colnames)\n",
    "df[\"path\"] = audio_path + df[\"path\"] + \".wav\"\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "7419be4c-fe00-44ce-a8c7-f31f86a5226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RATIO = 0.90 \n",
    "VAL_RATIO = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "26e47235-ed70-42a7-a165-09aff2b583d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "0b2f7f70-fc68-4e00-a500-321c095720c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, random_state = 0, train_size = TEST_RATIO)\n",
    "train_df, val_df = train_test_split(train_df, random_state = 0, train_size = VAL_RATIO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "facb0e77-2d27-4049-b9d5-628bb455fa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(csv_folder_path+'/train.csv',index=False)\n",
    "val_df.to_csv(csv_folder_path+'/val.csv',index=False)\n",
    "test_df.to_csv(csv_folder_path+'/test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "08a216af-7472-40b4-b4f0-9f35be13f5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./csv_files'"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "7e3fb765-9c0f-4072-a25d-dbb920f03c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    \"train\": \"train.csv\",\n",
    "    \"validation\": \"val.csv\",\n",
    "    \"test\": \"test.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "500ca59b-71c6-43c3-ae20-8f09ba843b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50934ebb53df465db9a0cea4a5f3daf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3bd013766241a8b7f253bf7c3237f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56b93327243423da130856c599b8f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = load_dataset(csv_folder_path, data_files = data_files, split = \"train\")\n",
    "val_data = load_dataset(csv_folder_path, data_files = data_files, split = \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "2ad78550-8155-4cfb-9f28-5672d6582a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "2d719a09-ac4d-4058-914e-286ec190e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "6ffba382-9be6-40b9-bc39-40014b4fd4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>विसं अठार सय बयालिस जेष्ठमा राजा सिद्धनारायण शाहको राज्यकालमा नेपाल एकीकरणमा गाभिएको पाइन्छ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>गायक दिपक सगंम सुदुर पश्चिमेली साङ्गीतिक क्षेत्रका महान् व्यक्ति हुन्</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>रुसको सङ्घीय विषय</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>अमेरिकी आवाज अभिनेता हास्य अभिनेता लेखक स्टोरीबोर्ड कलाकार एनिम बनाउने र निर्देशक</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ग्रिसमा रहेको सहर</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(train_data.remove_columns([\"path\"]), num_examples = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "71913a11-a296-406b-8820-723c70ef8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_to_ignore = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\ ]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "a3e5f89f-6e77-4660-9102-a38519341efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': './input/cleaned-asr-data/wavs/nep_2027_4847233647.wav',\n",
       " 'labels': 'ले शेर्पा भन्ने कम्पनीले यसको स्थापना देखि नै निरन्तर प्रगति गरिरहेको पाइन्छ'}"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "f59232e3-2ccb-45b4-863a-0def78b56c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(batch):\n",
    "    batch[\"labels\"] = re.sub(chars_to_ignore, '', batch[\"labels\"]).lower() + \" \"\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "eae74b0f-9748-4eaf-951e-f0505adf1749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "94d44e0d-727f-4a8d-918d-fd734716059b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1052d99aef9e48a6924d9f80d1f05043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720c4795d72942658a819d856895c86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/465 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_data.map(remove_special_characters)\n",
    "val_data = val_data.map(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "5972718f-3ee3-4aea-bc65-8a3cacf8cd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'labels'],\n",
       "    num_rows: 1392\n",
       "})"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "0f88cb81-2f81-4321-9127-c66396b4b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_all_chars(batch):\n",
    "#   all_text = \" \".join(batch[\"text\"])\n",
    "#   vocab = list(set(all_text))\n",
    "#   return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
    "\n",
    "# # vocabs = train_data['labels'].map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=timit.column_names[\"train\"])\n",
    "# batch = {\"text\": train_data['labels']}\n",
    "# result = extract_all_chars(batch)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "709ea7d3-3a03-401c-bdbd-2f11773bb358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# # Example train_data['labels'] (replace this with your actual data)\n",
    "# train_data = {\n",
    "#     'labels': [\"नेपाल\", \"शिक्षा\", \"संगीत\", \"कला\", \"स्वास्थ्य\"]\n",
    "# }\n",
    "\n",
    "# # Extract unique letters\n",
    "# unique_letters = set(\"\".join(train_data['labels']))\n",
    "\n",
    "# # Sort the letters (optional, for readability)\n",
    "# unique_letters = sorted(unique_letters)\n",
    "\n",
    "# # Save to JSON format\n",
    "# output_file = \"unique_letters.json\"\n",
    "# with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(unique_letters, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# print(f\"Unique letters saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "c036c239-401c-4061-a8e3-263869f450e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique letters\n",
    "# unique_letters = set(\"\".join(train_data['labels'])) ##THIS DOESN'T HAVE ENOUGH I GUESS SO...\n",
    "# Meaningful Nepali text\n",
    "# text = \"\"\"\n",
    "# नेपाल एक सुन्दर देश हो। हिमाल, पहाड र तराईको संगमले यो देशलाई अनौठो बनाएको छ। यहाँका मानिसहरू विभिन्न भाषाभाषी छन्। काठमाडौँ, पोखरा, धरान, र वीरगञ्ज प्रमुख सहरहरू हुन्।\n",
    "# नेपाली भाषा देशको आधिकारिक भाषा हो। ०१२३४५६७८९ अंकहरूले यहाँका सम्पूर्ण गन्तीहरूलाई सजिलो बनाउँछन्। हाम्रो राष्ट्रिय झण्डामा रातो र नीलो रंगको उपयोग गरिएको छ।\n",
    "# विद्यार्थीहरू पढाइमा ध्यान दिनुपर्छ। शिक्षकहरूले ज्ञानको उज्यालो फैलाउँछन्। बालबालिकाको भविष्य उज्ज्वल बनाउन शिक्षा अत्यन्त महत्वपूर्ण छ।\n",
    "# पर्यटकहरूले नेपालका हिमाल, मठमन्दिर, र हरियालीको आनन्द लिन्छन्। यहाँका चाडपर्वहरू जस्तै दशैँ, तिहार, र छठ सांस्कृतिक विविधताको परिचायक हुन्।\n",
    "# क्षेत्रीय र जातीय विविधताले हाम्रो समाजलाई बलियो बनाएको छ। सबै नेपालीको एकता हाम्रो राष्ट्रिय पहिचान हो।\n",
    "# \"\"\"\n",
    "# # Extract unique characters and sort them\n",
    "# unique_letters = sorted(set(text)) ##THIS ISN'T ENOUGH AS WELL I GUESS SO...\n",
    "unique_letters ={\n",
    "    \"[PAD]\": 0,\n",
    "    \"[UNK]\": 1,\n",
    "    \"|\": 2,\n",
    "    \"क\": 3,\n",
    "    \"ख\": 4,\n",
    "    \"ग\": 5,\n",
    "    \"घ\": 6,\n",
    "    \"ङ\": 7,\n",
    "    \"च\": 8,\n",
    "    \"छ\": 9,\n",
    "    \"ज\": 10,\n",
    "    \"झ\": 11,\n",
    "    \"ञ\": 12,\n",
    "    \"ट\": 13,\n",
    "    \"ठ\": 14,\n",
    "    \"ड\": 15,\n",
    "    \"ढ\": 16,\n",
    "    \"ण\": 17,\n",
    "    \"त\": 18,\n",
    "    \"थ\": 19,\n",
    "    \"द\": 20,\n",
    "    \"ध\": 21,\n",
    "    \"न\": 22,\n",
    "    \"प\": 23,\n",
    "    \"फ\": 24,\n",
    "    \"ब\": 25,\n",
    "    \"भ\": 26,\n",
    "    \"म\": 27,\n",
    "    \"य\": 28,\n",
    "    \"र\": 29,\n",
    "    \"ल\": 30,\n",
    "    \"व\": 31,\n",
    "    \"श\": 32,\n",
    "    \"ष\": 33,\n",
    "    \"स\": 34,\n",
    "    \"ह\": 35,\n",
    "    \"क्ष\": 36,\n",
    "    \"त्र\": 37,\n",
    "    \"ज्ञ\": 38,\n",
    "    \"अ\": 39,\n",
    "    \"आ\": 40,\n",
    "    \"इ\": 41,\n",
    "    \"ई\": 42,\n",
    "    \"उ\": 43,\n",
    "    \"ऊ\": 44,\n",
    "    \"ए\": 45,\n",
    "    \"ऐ\": 46,\n",
    "    \"ओ\": 47,\n",
    "    \"औ\": 48,\n",
    "    \"अं\": 49,\n",
    "    \"अः\": 50,\n",
    "    \"ा\": 51,\n",
    "    \"ि\": 52,\n",
    "    \"ी\": 53,\n",
    "    \"ु\": 54,\n",
    "    \"ू\": 55,\n",
    "    \"े\": 56,\n",
    "    \"ै\": 57,\n",
    "    \"ो\": 58,\n",
    "    \"ौ\": 59,\n",
    "    \"ं\": 60,\n",
    "    \"ः\": 61,\n",
    "    \"ँ\": 62,\n",
    "    \"०\": 63,\n",
    "    \"१\": 64,\n",
    "    \"२\": 65,\n",
    "    \"३\": 66,\n",
    "    \"४\": 67,\n",
    "    \"५\": 68,\n",
    "    \"६\": 69,\n",
    "    \"७\": 70,\n",
    "    \"८\": 71,\n",
    "    \"९\": 72\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "56d221e7-3418-43fe-9d7b-7616c187a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sort the letters (optional, for readability)\n",
    "# unique_letters = sorted(unique_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "f140661e-ef09-49ad-a0b1-d6cdfe7eb096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique letters saved to ./input/cleaned-asr-data/data/data/vocabulary/vocab.json\n"
     ]
    }
   ],
   "source": [
    "# Save to JSON format\n",
    "output_file = \"./input/cleaned-asr-data/data/data/vocabulary/vocab.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(unique_letters, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Unique letters saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "a660753e-d8e2-4735-a607-aa3157cf4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Path to your JSON file\n",
    "# file_path = \"./input/cleaned-asr-data/data/data/vocabulary/vocab.json\"\n",
    "\n",
    "# # Load and display JSON content\n",
    "# with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "# # Display the JSON content\n",
    "# print(json.dumps(data, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "ecb9ce42-3b71-499f-af6c-92e88430ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "d0e57bd4-9ebd-4aa2-81f6-f65fb3a30dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_path = './input/cleaned-asr-data/data/data/vocabulary/vocab.json'\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\n",
    "    vocab_path, \n",
    "    unk_token = \"[UNK]\", \n",
    "    pad_token = \"[PAD]\", \n",
    "    word_delimiter_token = \"|\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "b0292cfd-2f35-434f-afb8-43f342ced0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./tokenizer/tokenizer_config.json',\n",
       " './tokenizer/special_tokens_map.json',\n",
       " './tokenizer/vocab.json',\n",
       " './tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "4f40dee7-c02e-4f5f-b211-3b5d412448f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "a61d5e0d-4ced-4170-9c6d-113f0362bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = Wav2Vec2FeatureExtractor(\n",
    "    feature_size = 1, \n",
    "    sampling_rate = 16000, \n",
    "    padding_value = 0.0, \n",
    "    do_normalize = True, \n",
    "    return_attention_mask = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "054f2c1e-fbf8-4ded-8142-7111aa8dd697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "e1fad9da-bd91-43ea-acb5-12daa885be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor(\n",
    "    feature_extractor = feature_extractor, \n",
    "    tokenizer = tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "e5690460-3b11-40d1-bc48-1c23e9665035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.save_pretrained(processor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "b1075d54-eedb-42ee-b7d7-2306e8759273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': './input/cleaned-asr-data/wavs/nep_2027_4847233647.wav',\n",
       " 'labels': 'लेशेर्पाभन्नेकम्पनीलेयसकोस्थापनादेखिनैनिरन्तरप्रगतिगरिरहेकोपाइन्छ '}"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "3792d22b-24eb-41db-991d-26ee73cfbf16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': './input/cleaned-asr-data/wavs/nep_3154_8967733276.wav',\n",
       " 'labels': 'टिकापुरबहुमुखीक्याम्पसकैलालीजिल्लामारहेकोएउटाक्याम्पसहो '}"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "4bc3e77c-bcf5-4a36-a3ad-ae5f3cb87f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2+cpu'"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "cbd390f6-1e56-416c-91fc-5d64ac068903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "7efd1be7-6967-4aef-b820-03ee8aeea46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = speech_array[0].numpy()\n",
    "    batch[\"sampling_rate\"] = sampling_rate\n",
    "    batch[\"target_text\"] = batch[\"labels\"]\n",
    "    \n",
    "    resampler = torchaudio.transforms.Resample(sampling_rate, 16000)\n",
    "    batch[\"speech\"] = resampler(speech_array).squeeze().numpy()\n",
    "    batch[\"sampling_rate\"] = 16000\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "d4fe1b57-8a12-44af-89ac-975a17b7eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.map(speech_file_to_array_fn, remove_columns=train_data.column_names)\n",
    "val_data = val_data.map(speech_file_to_array_fn, remove_columns=val_data.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4df057-4899-49fc-bcf9-0dee0340b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d3bf68-4875-4d2c-aa3a-2158b9b9d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio  # Import the Audio class\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b81c0fa-2493-45d0-81ef-5157c1713ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_int = random.randint(0, len(train_data) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9d9b2-8344-47c7-91ee-dd118765f744",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data = np.asarray(\n",
    "    train_data[rand_int][\"speech\"]), \n",
    "    autoplay = True, \n",
    "    rate = 16000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8e2f6f7c-28f2-49e2-bb1f-8e231c619788",
   "metadata": {},
   "outputs": [],
   "source": [
    " # train_data[rand_int][\"target_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f2e08ea0-b1dc-421d-819a-d12c0f43d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data[rand_int][\"speech\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "846d5a47-8bf6-48b5-a533-e682625b5a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand_int = random.randint(0, len(train_data) - 1)\n",
    "\n",
    "# print(\"Target text:\", train_data[rand_int][\"target_text\"])\n",
    "# print(\"Input array shape:\", np.asarray(train_data[rand_int][\"speech\"]).shape)\n",
    "# print(\"Sampling rate:\", train_data[rand_int][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9dc6aa11-3dee-46b7-b3cc-efa710d85ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a1a81b15-3c9a-4e88-8872-deefdb44283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch, processor):\n",
    "        \n",
    "    # check that all files have the correct sampling rate\n",
    "    assert (\n",
    "        len(set(batch[\"sampling_rate\"])) == 1\n",
    "    ), f\"Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}.\"\n",
    "\n",
    "    batch[\"input_values\"] = processor(batch[\"speech\"], sampling_rate = batch[\"sampling_rate\"][0]).input_values\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"target_text\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c924f247-ad58-4824-9905-b221f55fe345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653177fc0e8f459783ab3d72dc560a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5c7bd519b140aab6f8c4c58576939a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/465 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = train_data.map(prepare_dataset, fn_kwargs = {\"processor\": processor}, remove_columns = train_data.column_names, batch_size = 8, num_proc = 4, batched = True)\n",
    "val_data = val_data.map(prepare_dataset, fn_kwargs = {\"processor\": processor}, remove_columns = val_data.column_names, batch_size = 8, num_proc = 4, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b169a4b2-b1db-40d8-864b-83aea93946cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "974836a0-45a3-42fd-9ef6-6cb2ca625c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3943b3ea-8a4f-47a5-afa6-09fb84ebf817",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor = processor, padding = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c5473c99-3c6b-4f7b-9688-aab7dcbaf098",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = load(\"wer\")\n",
    "cer_metric = load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "477627fd-dea5-452c-a318-139223664b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    \n",
    "    # cer_best = 1 - cer because load best model is considering greater value of cer for better results\n",
    "    cer_best = 1 - cer\n",
    "    # wandb.log({'wer':wer, 'cer':cer})\n",
    "    # experiment.log_metric('wer', wer)\n",
    "    # experiment.log_metric('cer', cer)\n",
    "    \n",
    "    return {\"wer\": wer, \"cer\": cer, \"cer_best\": cer_best}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ad46a815-1029-40d6-9f1b-f4fd9d8490db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1394c544-0f27-4e11-b557-374efa165579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-xlsr-53\", \n",
    "    attention_dropout = 0.1,\n",
    "    hidden_dropout = 0.1,\n",
    "    feat_proj_dropout = 0.0,\n",
    "    mask_time_prob = 0.05,\n",
    "    layerdrop = 0.1,\n",
    "    gradient_checkpointing = True, \n",
    "    ctc_loss_reduction = \"mean\", \n",
    "    pad_token_id = processor.tokenizer.pad_token_id,\n",
    "    vocab_size = len(processor.tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "79fccd9d-dcd8-46cd-a6cf-ab321e719841",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_feature_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8caf4002-474c-4c9e-9746-2cea7235b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8d04684a-92aa-4704-9fc6-5fad0e0c8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "65fce13c-d302-452d-8a47-811426cb6a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7e57ebbe-5069-4646-a7b7-938dc1c74787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "02ee4d72-9a72-4f46-b56e-ec2c83493db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"checkpoints_path\",  # Path to save training checkpoints\n",
    "    group_by_length=True,  # Group training examples by similar length\n",
    "    per_device_train_batch_size=16,  # Training batch size per device\n",
    "    gradient_accumulation_steps=2,  # Accumulate gradients over 2 steps\n",
    "    eval_strategy=\"steps\",  # Evaluate every \"eval_steps\" steps\n",
    "    num_train_epochs=30,  # Number of training epochs\n",
    "    # fp16=True,  # Use mixed precision training\n",
    "    fp16=False,  # Use mixed precision training\n",
    "    save_steps=50,  # Save model checkpoints every 50 steps\n",
    "    eval_steps=50,  # Evaluate model performance every 50 steps\n",
    "    logging_steps=50,  # Log training information every 50 steps\n",
    "    learning_rate=3e-4,  # Initial learning rate\n",
    "    warmup_steps=180,  # Warmup steps for learning rate scheduler\n",
    "    save_total_limit=2,  # Keep only the 2 best checkpoints\n",
    "    overwrite_output_dir=True,  # Overwrite existing output directory\n",
    "    gradient_checkpointing=True,  # Enable gradient checkpointing\n",
    "    metric_for_best_model=\"cer_best\",  # Metric to choose the best model\n",
    "    load_best_model_at_end=True  # Load the best model at the end for evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "be7cd483-a81e-4d2a-acba-71f7873f9c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9742c357-8e78-4661-a1a5-22c621449022",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    data_collator = data_collator,\n",
    "    args = training_args,\n",
    "    compute_metrics = compute_metrics,\n",
    "    train_dataset = train_data,\n",
    "    eval_dataset = val_data,\n",
    "    tokenizer = processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "50beec38-8a63-49f2-b164-355aa2b277e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80789102-21e5-4f38-9b47-9200fe5550d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
